{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from six.moves import cPickle\n",
    "import scipy.ndimage as nd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as mpl_colors\n",
    "from GAIN import GAIN\n",
    "from SEC import SEC\n",
    "from dataset import dataset\n",
    "\n",
    "%matplotlib inline\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "class Inference_GAIN(GAIN):\n",
    "    def inference(self, batch_size, gpu_frac, eps=1e-5):\n",
    "        self.cmap = mpl_colors.LinearSegmentedColormap.from_list('Custom cmap', [\n",
    "            (0.0, 0.0, 0.0), (0.5, 0.0, 0.0), (0.0, 0.5, 0.0), (0.5, 0.5, 0.0),\n",
    "            (0.0, 0.0, 0.5), (0.5, 0.0, 0.5), (0.0, 0.5, 0.5), (0.5, 0.5, 0.5),\n",
    "            (0.25, 0.0, 0.0), (0.75, 0.0, 0.0), (0.25, 0.5, 0.0), (0.75, 0.5, 0.0),\n",
    "            (0.25, 0.0, 0.5), (0.75, 0.0, 0.5), (0.25, 0.5, 0.5), (0.75, 0.5, 0.5),\n",
    "            (0.0, 0.25, 0.0), (0.5, 0.25, 0.0), (0.0, 0.75, 0.0), (0.5, 0.75, 0.0),\n",
    "            (0.0, 0.25, 0.5)], 21)\n",
    "        gpu_options = tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=gpu_frac))\n",
    "        self.sess = tf.Session(config=gpu_options)\n",
    "        x, gt, _, _, id_of_image, iterator_train = self.data.next_batch(category=\"train\",batch_size=batch_size,epoches=-1)\n",
    "        self.build()\n",
    "        self.saver[\"norm\"] = tf.train.Saver(max_to_keep=2,var_list=self.trainable_list)\n",
    "        with self.sess.as_default():\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            self.sess.run(tf.local_variables_initializer())\n",
    "            self.sess.run(iterator_train.initializer)\n",
    "            if self.config.get(\"model_path\",False) is not False: self.restore_from_model(self.saver[\"norm\"], self.config.get(\"model_path\"), checkpoint=False)\n",
    "            epoch, i, iterations_per_epoch_train = 0.0, 0, self.data.get_data_len()//batch_size\n",
    "            while epoch < 1:\n",
    "                data_x, data_gt, img_id = self.sess.run([x, gt, id_of_image])\n",
    "                params = {self.net[\"input\"]:data_x, self.net[\"drop_prob\"]:0.5}\n",
    "                preds = self.sess.run(self.net[\"fc8-softmax\"], feed_dict=params)\n",
    "                for pred in preds:\n",
    "                    cimg_id = img_id[0].decode(\"utf-8\")\n",
    "                    if not os.path.exists('sec-preds/{}.png'.format(cimg_id)):\n",
    "                        continue\n",
    "                    img = Image.open(\"data/VOCdevkit/VOC2012/JPEGImages/{}.jpg\".format(cimg_id)).resize((321,321), Image.ANTIALIAS)\n",
    "                    scores_exp = np.exp(pred-np.max(pred, axis=2, keepdims=True))\n",
    "                    probs = scores_exp/np.sum(scores_exp, axis=2, keepdims=True)\n",
    "                    probs = nd.zoom(probs, (321/probs.shape[0], 321/probs.shape[1], 1.0), order=1)\n",
    "                    probs[probs<eps] = eps\n",
    "                    mask = np.argmax(probs, axis=2)\n",
    "                    \n",
    "                    fig = plt.figure(figsize=(20,20))\n",
    "                    ax1, ax2, ax3, ax4 = fig.add_subplot('141'), fig.add_subplot('142'), fig.add_subplot('143'), fig.add_subplot('144')\n",
    "                    ax1.imshow(img)\n",
    "                    ax2.imshow(cPickle.load(open(\"sec-preds/{}.png\".format(cimg_id), 'rb')), , vmin=0, vmax=21, cmap=self.cmap)\n",
    "                    ax3.matshow(mask, vmin=0, vmax=21, cmap=self.cmap)\n",
    "                    ax4.imshow(data_gt.reshape((321,321)), cmap='gray')\n",
    "                    ax1.set_title(\"image\")\n",
    "                    ax2.set_title(\"sec\")\n",
    "                    ax3.set_title(\"gain\")\n",
    "                    ax4.set_title(\"gt_mask\")\n",
    "                    ax1.set_axis_off()\n",
    "                    ax2.set_axis_off()\n",
    "                    ax3.set_axis_off()\n",
    "                    ax4.set_axis_off()\n",
    "                    plt.show()\n",
    "                i+=1\n",
    "                epoch = i/iterations_per_epoch_train\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "ckpt_path = \"gain-saver/norm-2999\"\n",
    "gain = Inference_GAIN({\"data\":dataset({\"batch_size\":1, \"input_size\":(321,321), \"epoches\":30, \"category_num\":21, \"categorys\":[\"train\"]}), \"batch_size\":1, \"input_size\":(321,321), \"epoches\":30, \"category_num\":21, \"model_path\":ckpt_path, \"accum_num\":16})\n",
    "gain.inference(1,0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEC Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len:{'train': 10582}\n",
      "INFO:tensorflow:Restoring parameters from sec-saver/norm-56999\n"
     ]
    }
   ],
   "source": [
    "class Inference_SEC(SEC):\n",
    "    def inference(self, batch_size, gpu_frac, eps=1e-5):\n",
    "        self.cmap = mpl_colors.LinearSegmentedColormap.from_list('Custom cmap', [\n",
    "            (0.0, 0.0, 0.0), (0.5, 0.0, 0.0), (0.0, 0.5, 0.0), (0.5, 0.5, 0.0),\n",
    "            (0.0, 0.0, 0.5), (0.5, 0.0, 0.5), (0.0, 0.5, 0.5), (0.5, 0.5, 0.5),\n",
    "            (0.25, 0.0, 0.0), (0.75, 0.0, 0.0), (0.25, 0.5, 0.0), (0.75, 0.5, 0.0),\n",
    "            (0.25, 0.0, 0.5), (0.75, 0.0, 0.5), (0.25, 0.5, 0.5), (0.75, 0.5, 0.5),\n",
    "            (0.0, 0.25, 0.0), (0.5, 0.25, 0.0), (0.0, 0.75, 0.0), (0.5, 0.75, 0.0),\n",
    "            (0.0, 0.25, 0.5)], 21)\n",
    "        gpu_options = tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=gpu_frac))\n",
    "        self.sess = tf.Session(config=gpu_options)\n",
    "        x, gt, _, _, id_of_image, iterator_train = self.data.next_batch(category=\"train\",batch_size=batch_size,epoches=-1)\n",
    "        self.build()\n",
    "        self.saver[\"norm\"] = tf.train.Saver(max_to_keep=2,var_list=self.trainable_list)\n",
    "        with self.sess.as_default():\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            self.sess.run(tf.local_variables_initializer())\n",
    "            self.sess.run(iterator_train.initializer)\n",
    "            if self.config.get(\"model_path\",False) is not False: self.restore_from_model(self.saver[\"norm\"], self.config.get(\"model_path\"), checkpoint=False)\n",
    "            epoch, i, iterations_per_epoch_train = 0.0, 0, self.data.get_data_len()//batch_size\n",
    "            while epoch < 1:\n",
    "                data_x, data_gt, img_id = self.sess.run([x, gt, id_of_image])\n",
    "                params = {self.net[\"input\"]:data_x, self.net[\"drop_prob\"]:0.5}\n",
    "                preds = self.sess.run(self.net[\"fc8-softmax\"], feed_dict=params)\n",
    "                for pred in preds:\n",
    "                    img = Image.open(\"data/VOCdevkit/VOC2012/JPEGImages/{}.jpg\".format(img_id[0].decode(\"utf-8\"))).resize((321,321), Image.ANTIALIAS)\n",
    "                    scores_exp = np.exp(pred-np.max(pred, axis=2, keepdims=True))\n",
    "                    probs = scores_exp/np.sum(scores_exp, axis=2, keepdims=True)\n",
    "                    probs = nd.zoom(probs, (321/probs.shape[0], 321/probs.shape[1], 1.0), order=1)\n",
    "                    probs[probs<eps] = eps\n",
    "                    mask = np.argmax(probs, axis=2)\n",
    "                    cPickle.dump(mask, open('sec-preds/{}.pkl'.format(img_id[0].decode(\"utf-8\")), 'wb'))\n",
    "                i+=1\n",
    "                epoch = i/iterations_per_epoch_train\n",
    "\n",
    "\"\"\"\n",
    "ckpt_path = \"sec-saver/norm-56999\"\n",
    "sec = Inference_SEC({\"data\":dataset({\"batch_size\":1, \"input_size\":(321,321), \"epoches\":30, \"category_num\":21, \"categorys\":[\"train\"]}), \"batch_size\":1, \"input_size\":(321,321), \"epoches\":30, \"category_num\":21, \"model_path\":ckpt_path, \"accum_num\":16})\n",
    "sec.inference(1,0.05)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
